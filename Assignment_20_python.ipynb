{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8882145f-6ba3-402f-a51f-ff452e8c17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "\"\"\"\n",
    "Web scraping is the extraction of data from websites.\n",
    "It is used to gather information for analysis, research, or to automate tasks. \n",
    "Common areas where web scraping is employed include data mining, competitive intelligence, and market research.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ce665-a4d4-4733-965b-71dea42d82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "\"\"\"\n",
    "HTML Parsing: Parsing the HTML structure of a website using libraries like BeautifulSoup to extract relevant data.\n",
    "API Access: Accessing a website's API directly to retrieve data in a structured format, if available.\n",
    "Automated Browsing: Utilizing web automation tools like Selenium to simulate human interaction with the website and \n",
    "extract data dynamically loaded through JavaScript. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace75d1-71a5-42eb-be2b-eee45915bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## what is beautifulsoup and why it is used ?\n",
    "\"\"\" \n",
    "Beautiful Soup is a Python library used for parsing HTML and XML documents, \n",
    "making it easier to extract data from web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52831bc7-35db-4237-afab-6f8a576d2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "\"\"\"Flask is used in web scraping projects to create a \n",
    "web application that can display or process the scraped data. \n",
    "It offers a approach to building web interfaces and handling HTTP requests. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a217c3-d2f0-459d-9e79-9a4a02169648",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\"\"\"\n",
    "Amazon EC2 : It provides virtual server instances in the cloud\n",
    "Amazon lambda : Lambda can be employed to execute the web scraping code in a serverless environmen\n",
    "Amazon Glue : Glue is an ETL (Extract, Transform, Load) service that can be employed to preprocess \n",
    "or transform the scraped data before storing it.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
